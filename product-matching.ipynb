{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выполнил Сенин Александр (aaasenin@gmail.com)\n",
    "\n",
    "Время выполнения - три дня.\n",
    "\n",
    "*28.10.21*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Условие\n",
    "\n",
    "Даны данные одного крупного онлайн магазина, перед которым стоит классическая задача продуктового мачинга. У магазина много поставщиков одинаковых товаров и все они называют их по разному, задача найти одни и те же товары с разными названиями и объединить их в группы.\n",
    "\n",
    "Для каждого товара нужно выдать список товаров которые модель считает одинаковыми. При этом таких товаров не может быть более 50 для одной группы. Метрикой для задачи будет среднее построчного F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "yKz4Vu6qCf9w"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8PHatWupCf96",
    "outputId": "e3dfe08a-2efb-447b-904a-d3b9ff4a2a8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20952, 3)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "I_2Bv2-rCf97",
    "outputId": "3038489a-b169-4ca8-8e0e-2931b2d6e573"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_2278313361</td>\n",
       "      <td>PAPER BAG VICTORIA SECRET</td>\n",
       "      <td>249114794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3803689425</td>\n",
       "      <td>Maling Ham Pork Luncheon Meat TTS 397gr</td>\n",
       "      <td>2395904891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                              title  \\\n",
       "0   train_129225211                          Paper Bag Victoria Secret   \n",
       "1  train_2278313361                          PAPER BAG VICTORIA SECRET   \n",
       "2  train_2288590299        Maling TTS Canned Pork Luncheon Meat 397 gr   \n",
       "3  train_3803689425            Maling Ham Pork Luncheon Meat TTS 397gr   \n",
       "4  train_2406599165  Daster Batik Lengan pendek - Motif Acak / Camp...   \n",
       "\n",
       "   label_group  \n",
       "0    249114794  \n",
       "1    249114794  \n",
       "2   2395904891  \n",
       "3   2395904891  \n",
       "4   4093212188  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5RAjcv0Cf97",
    "outputId": "6adc5bc5-754e-4482-ab2b-491d3327f85c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6608,)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label_group.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "id": "Oe0NXI3VCf98"
   },
   "outputs": [],
   "source": [
    "tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
    "df['matches'] = df['label_group'].map(tmp)\n",
    "df['matches'] = df['matches'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmYLfOg7Cf99"
   },
   "source": [
    "Метрикой будет построчный f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "id": "_6CEnJC7Cf9-"
   },
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiWnvryuCf9_"
   },
   "source": [
    "В качестве бейзлайна сопоставим себя в группу только с самим собой и каким-нибудь еще одним случайным товаром."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "id": "cS0c12fyCf-A"
   },
   "outputs": [],
   "source": [
    "df['prediction'] = df['posting_id'] + ' ' + 'train_129225211'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "id": "7RmmAUt-Cf-A"
   },
   "outputs": [],
   "source": [
    "y_true = df['matches']\n",
    "y_pred = df['prediction']\n",
    "y_true = y_true.apply(lambda x: set(x.split()))\n",
    "y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyDelyt3Cf-B",
    "outputId": "43b7986b-0fcc-44d8-eff1-a2d69bbaa42f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35675992543848534"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df['matches'], df['prediction']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8U2aUnnECf-C"
   },
   "source": [
    "Цель - улучшить эту метрику."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Imports***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ErKqKmSwCf91",
    "outputId": "5af3f2cc-bef6-42fc-9e44-c6a1b8fd0397"
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install metric-learn\n",
    "#!{sys.executable} -m pip install jellyfish\n",
    "#!{sys.executable} -m pip install fuzzywuzzy\n",
    "#!{sys.executable} -m pip install stopwords\n",
    "#!{sys.executable} -m pip install pytorch_metric_learning\n",
    "#!{sys.executable} -m pip install python_levenshtein\n",
    "#!{sys.executable} -m pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A51PKaI1Ck1L",
    "outputId": "be706129-155e-4e16-f430-08555db7fac8"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#path = '/content/drive/My Drive/train_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "id": "5hg1Un9lCf93"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm \n",
    "from itertools import combinations\n",
    "\n",
    "import string\n",
    "import re\n",
    "import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import FastText, Word2Vec\n",
    "import jellyfish as jf\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from sklearn.metrics import f1_score as f1_sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# import os\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "id": "gZdtatBJCf94"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-awUSeVYCf95",
    "outputId": "f91b7538-1f81-429b-a518-657b3b2d18b0"
   },
   "outputs": [],
   "source": [
    "from metric_learn import RCA\n",
    "from pytorch_metric_learning import samplers, losses, reducers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "id": "pfcVj6kECf95"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2k44IX_WCf-C"
   },
   "source": [
    "***Немного EDA***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В архиве помимо train_data.csv лежит test_data.csv, но там нет таргета (что логично). Поэтому, работаем только с train_data.csv, а для оценки качества поступаем так:\n",
    "- В случае unsupervised методов оцениваемся на всей выборке\n",
    "- В случае supervised методов откладываем валидационную выборку размера 0.2~0.3 от общей и оцениваемся на ней"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLlDVEiBCf-D",
    "outputId": "a4e636d5-cf54-48c7-c9fb-7fb7e4a0c886"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20952,)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"posting_id\"].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI_QoFItCf-E"
   },
   "source": [
    "Совпадает с размером датасета, значит posting_id - честный уникальный айди."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на распределение длины таргета (колонки matches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "id": "gCJMtGdOCf-E"
   },
   "outputs": [],
   "source": [
    "df[\"matches_len\"] = df[\"matches\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "2OePvSktCf-F",
    "outputId": "714703b8-c1e8-4752-a0c3-03a80039c422"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"matches_len\"].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 8к случаев таргет длины 2. Учитываем, что в таргете для каждого объекта уже есть айди этого же объекта. То есть в 8к случаев у объекта есть всего один сосед, которого нужно найти.\n",
    "\n",
    "Из этих соображений понятно, почему значение F1 на бейзлайне - 0.35. В 8к случаев у нас уже есть половина ответа (в предсказание протекает айди самого объекта). Поэтому, возможно, лучше было бы считать F1 на ответах без айди самого объекта.\n",
    "\n",
    "Еще заметим, что у большей половины объектов длина таргета не превосходит 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t884l3tWCf-G"
   },
   "source": [
    "Посмотрим на самый большой (и самый редкий) кластер (множество объектов с одинаковым таргетом, причем длина этого таргета максимальна в данном случае)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "3k9gMgN4Cf-H",
    "outputId": "9555758e-368a-4611-cfab-83a2f00c09a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>matches</th>\n",
       "      <th>prediction</th>\n",
       "      <th>matches_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>train_2648609819</td>\n",
       "      <td>Bee123 Kain lap kanebo</td>\n",
       "      <td>821583868</td>\n",
       "      <td>train_2648609819 train_3784133722 train_236576...</td>\n",
       "      <td>train_2648609819 train_129225211</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>train_3784133722</td>\n",
       "      <td>KANEBO SERAT SERAP AIR / LAP KAIN KANEBO MURAH...</td>\n",
       "      <td>821583868</td>\n",
       "      <td>train_2648609819 train_3784133722 train_236576...</td>\n",
       "      <td>train_3784133722 train_129225211</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>train_2365762721</td>\n",
       "      <td>KANEBO SERAT SUPER TEBAL HALUS</td>\n",
       "      <td>821583868</td>\n",
       "      <td>train_2648609819 train_3784133722 train_236576...</td>\n",
       "      <td>train_2365762721 train_129225211</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>train_3276258443</td>\n",
       "      <td>Kanebo Refil Polos Sedang - Grosir - AION Plas...</td>\n",
       "      <td>821583868</td>\n",
       "      <td>train_2648609819 train_3784133722 train_236576...</td>\n",
       "      <td>train_3276258443 train_129225211</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            posting_id                                              title  \\\n",
       "1066  train_2648609819                             Bee123 Kain lap kanebo   \n",
       "1067  train_3784133722  KANEBO SERAT SERAP AIR / LAP KAIN KANEBO MURAH...   \n",
       "1068  train_2365762721                     KANEBO SERAT SUPER TEBAL HALUS   \n",
       "1069  train_3276258443  Kanebo Refil Polos Sedang - Grosir - AION Plas...   \n",
       "\n",
       "      label_group                                            matches  \\\n",
       "1066    821583868  train_2648609819 train_3784133722 train_236576...   \n",
       "1067    821583868  train_2648609819 train_3784133722 train_236576...   \n",
       "1068    821583868  train_2648609819 train_3784133722 train_236576...   \n",
       "1069    821583868  train_2648609819 train_3784133722 train_236576...   \n",
       "\n",
       "                            prediction  matches_len  \n",
       "1066  train_2648609819 train_129225211           26  \n",
       "1067  train_3784133722 train_129225211           26  \n",
       "1068  train_2365762721 train_129225211           26  \n",
       "1069  train_3276258443 train_129225211           26  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"matches_len\"] == 26].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wG6XxSOOCf-H"
   },
   "source": [
    "Во всех названиях есть слово \"kanebo\". Посмотрим на объекты с таргетом длины 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "UompZ7A3Cf-I",
    "outputId": "a8f2fa07-12f1-4349-d8e3-a6a593c5f77c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>matches</th>\n",
       "      <th>prediction</th>\n",
       "      <th>matches_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>train_129225211 train_2278313361</td>\n",
       "      <td>train_129225211 train_129225211</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_2278313361</td>\n",
       "      <td>PAPER BAG VICTORIA SECRET</td>\n",
       "      <td>249114794</td>\n",
       "      <td>train_129225211 train_2278313361</td>\n",
       "      <td>train_2278313361 train_129225211</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "      <td>train_2288590299 train_3803689425</td>\n",
       "      <td>train_2288590299 train_129225211</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3803689425</td>\n",
       "      <td>Maling Ham Pork Luncheon Meat TTS 397gr</td>\n",
       "      <td>2395904891</td>\n",
       "      <td>train_2288590299 train_3803689425</td>\n",
       "      <td>train_3803689425 train_129225211</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "      <td>train_2406599165 train_3342059966</td>\n",
       "      <td>train_2406599165 train_129225211</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_3342059966</td>\n",
       "      <td>DASTER PIYAMA KATUN JEPANG(TIDAK BISA PILIH MO...</td>\n",
       "      <td>4093212188</td>\n",
       "      <td>train_2406599165 train_3342059966</td>\n",
       "      <td>train_3342059966 train_129225211</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                              title  \\\n",
       "0   train_129225211                          Paper Bag Victoria Secret   \n",
       "1  train_2278313361                          PAPER BAG VICTORIA SECRET   \n",
       "2  train_2288590299        Maling TTS Canned Pork Luncheon Meat 397 gr   \n",
       "3  train_3803689425            Maling Ham Pork Luncheon Meat TTS 397gr   \n",
       "4  train_2406599165  Daster Batik Lengan pendek - Motif Acak / Camp...   \n",
       "5  train_3342059966  DASTER PIYAMA KATUN JEPANG(TIDAK BISA PILIH MO...   \n",
       "\n",
       "   label_group                            matches  \\\n",
       "0    249114794   train_129225211 train_2278313361   \n",
       "1    249114794   train_129225211 train_2278313361   \n",
       "2   2395904891  train_2288590299 train_3803689425   \n",
       "3   2395904891  train_2288590299 train_3803689425   \n",
       "4   4093212188  train_2406599165 train_3342059966   \n",
       "5   4093212188  train_2406599165 train_3342059966   \n",
       "\n",
       "                         prediction  matches_len  \n",
       "0   train_129225211 train_129225211            2  \n",
       "1  train_2278313361 train_129225211            2  \n",
       "2  train_2288590299 train_129225211            2  \n",
       "3  train_3803689425 train_129225211            2  \n",
       "4  train_2406599165 train_129225211            2  \n",
       "5  train_3342059966 train_129225211            2  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"matches_len\"] == 2].head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nehgq9zoCf-I"
   },
   "source": [
    "Здесь аналогично, есть небольшие пересечения некоторых уникальных слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HX8wTLGcCf-J"
   },
   "source": [
    "### Простое ML решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIa0_fSaCf-J"
   },
   "source": [
    "Возникает первая плодотворная идея. Хотим обращать внимание на пересечение редких слов - тут подойдет tf-idf, особенно важен множитель idf - он и даст степень редкости. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "id": "0FuRLCvmCf-J"
   },
   "outputs": [],
   "source": [
    "df[\"pure_matches\"] = (df[\"matches\"].apply(lambda x: set(x.split())) - \\\n",
    "                      df[\"posting_id\"].apply(lambda x: set([x]))).apply(lambda x: ''.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "id": "7Nmso2wrCf-K"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "X = tfidf.fit_transform(df['title'])\n",
    "y = df[\"label_group\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q90Az9E2Cf-L"
   },
   "source": [
    "Построим для каждого объекта tf-idf представление. Воспользуемся тем, что в длина таргета 2 - очень популярна. Будем предсказывать одного ближайшего соседа в пространстве tf-idf (если в двух заголовках одного и того же товара есть общие уникальные слова, то их tf-idf представления будут похожи)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "id": "qKPMbra-Cf-N"
   },
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "id": "1ngnUiX9Cf-P"
   },
   "outputs": [],
   "source": [
    "df[\"knn_pred\"] = \"\"\n",
    "for i, val in enumerate(indices):\n",
    "    df[\"knn_pred\"].iloc[i] = f\"{df['posting_id'].iloc[val[0]]} {df['posting_id'].iloc[val[1]]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5jzVBDwCf-Q",
    "outputId": "9ff5c226-90fe-4800-a8e9-4ba2d34144dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6081975535382363"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df['matches'], df['knn_pred']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzmgkA8QCf-R"
   },
   "source": [
    "**Качество выросло в 2 раза - 0.61**. Ключевой недостаток - предсказываем ответ фиксированной длины 2, а он, вообще говоря, произволен. Если это исправить, потенциально можно получить качество больше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GojdJscACf-R"
   },
   "source": [
    "Можно даже посчитать метрику (качество) на объектах, для которых таргет действительно длины 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "id": "b9WCe8QqCf-R"
   },
   "outputs": [],
   "source": [
    "base_df = df[df[\"matches_len\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "id": "Aosc3JV-Cf-S"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "X = tfidf.fit_transform(base_df['title'])\n",
    "y = base_df[\"label_group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "22co-q2QCf-S"
   },
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "id": "nf4du0OQCf-T"
   },
   "outputs": [],
   "source": [
    "base_df[\"knn_pred\"] = \"\"\n",
    "for i, val in enumerate(indices):\n",
    "    base_df[\"knn_pred\"].iloc[i] = f\"{base_df['posting_id'].iloc[val[0]]} {base_df['posting_id'].iloc[val[1]]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dQiujUldCf-U",
    "outputId": "1bca73d3-e2ea-4fc8-8d07-7d7f35b1a4fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8616534104603519"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(base_df['matches'], base_df['knn_pred']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEZpUnHCCf-U"
   },
   "source": [
    "**Только на таргетах длины 2 - качество 0.86**. Действительно, метрика сильно проседает из-за предположения о фиксированной длине таргета. Это хороший знак - задача хорошо ложится под построение эмбеддингов и нахождение кластеров каким-нибудь расстоянием. Даже в случае, когда в качестве эмбеддингов используется tf-idf представление вместе с евклидовым расстоянием (которое, вообще говоря, не обязано хорошо работать на сильно разреженных векторах tf-idf огромной размерности) - уже получается неплохое качество. \n",
    "\n",
    "Важное замечание: kNN (1NN) никак не использовал таргет, только tf-idf представления, то есть это чистое unsupervised решение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введем метки кластеров (на самом деле они уже были в оригинальном датасете, поэтому просто нумеруем заново)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "Bjr_ayDtCf-X"
   },
   "outputs": [],
   "source": [
    "del df[\"label_group\"]\n",
    "\n",
    "matches_to_labels = {}\n",
    "label = 0\n",
    "matches_tupled = df[\"matches\"].apply(lambda x: tuple(sorted(x.split())))\n",
    "for key in matches_tupled.values:\n",
    "    if key not in matches_to_labels:\n",
    "        matches_to_labels[key] = label\n",
    "        label += 1\n",
    "        \n",
    "df[\"label\"] = matches_tupled.apply(lambda x: matches_to_labels[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2J7M2Q9Cf-Y"
   },
   "source": [
    "***Text preprocessing***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем более сложное решение. Работаем с текстами - нужен препроцессинг. Удаляем пунктуацию, стопслова, приводим к одному регистру, лемматизируем и токенизируем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "-FgNjRmHCf-Y"
   },
   "outputs": [],
   "source": [
    "extended_punctuation = \"\"\"'!\"#$%&\\'()*,-/:;®™<=>?@[\\\\]^_`{|}~+\"\"\"\n",
    "\n",
    "def remove_punct(s):\n",
    "    return \"\".join([char for char in s if char not in extended_punctuation])\n",
    "\n",
    "def lower(s):\n",
    "    return s.lower()\n",
    "\n",
    "def reduce_spaces(s):\n",
    "    return re.sub(' +', ' ', s)\n",
    "\n",
    "def tokenize(s):\n",
    "    s = s.replace(\".\", \" \")\n",
    "    return s.split()\n",
    "\n",
    "def filter_stop_words(tokens):\n",
    "    stop_words = stopwords.get_stopwords(\"english\")\n",
    "    return [token for token in tokens if token not in stop_words]\n",
    "\n",
    "def stem(tokens):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "   \n",
    "def lemmatize(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "def preproc(s):\n",
    "    clean_s = reduce_spaces(remove_punct(lower(s)))\n",
    "    tokens = lemmatize(filter_stop_words(tokenize(clean_s)))\n",
    "    return np.array(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Gw2nDTRICf-Z"
   },
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "df['text'] = df['title'].apply(lambda x: preproc(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2gCECYWCf-a"
   },
   "source": [
    "### DL решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишем мотивацию выбора архитектуры.\n",
    "\n",
    "Хотим применить нейронки. Пусть с помощью нейронки для каждого объекта (суть заголовка товара) можем получить эмбеддинг. Тогда в пространстве эмбеддингов сможем найти кластеры объектов. Это могут быть как кластеры размера 2 (пары объектов, та же идея с 1NN), это могут быть и кластеры произвольного размера. В теории по эмбеддингам можем посчитать расстояния на парах объектов, а затем по некоторому порогу определять соседей. Другими словами, для каждого объекта будем относить в один с ним кластер все объекты в шаре (в случае евклидовой метрики) некоторого радиуса (который и определяется порогом) с центром в эмбеддинге этого объекта. Подход с кластером размера 2 будем называть 1NN, подход с варьированием порога - adaptive neighbors (адаптивный в смысле перебора порога).\n",
    "\n",
    "Осталось обучить нейронку строить эмбеддинги..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на число слов в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "E98GK8eDCf-a"
   },
   "outputs": [],
   "source": [
    "def vocab(series):\n",
    "    return {\n",
    "        token\n",
    "        for tokens in series.values\n",
    "            for token in tokens\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rm_9zptGCf-b",
    "outputId": "27ed8b22-65d0-44b5-baa5-c38c72395599"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19987"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab(df['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почти 20к, причем в валидационной (тестовой) выборке могут оказаться незнакомые слова. Более того, среди этих 20к слов много уникальных (крайне редко встречающихся). Например, название каких-нибудь уникальных наушников (которое встретится в худшем случае всего 2 раза в выборке) Sony в духе \"Sony Wireless Z Ultra C6833 HX-mk2\" породит слова \"C6833\" и \"HX-mk2\".\n",
    "\n",
    "В этих условиях, строить эмбеддинг заголовка на базе его слов проблематично. За единицу отсчета возьмем символы. Посимвольные RNN-ки тоже неплохо работают, и даже умеют генерить полуосмысленный текст, если обучать их предсказывать следующий символ.\n",
    "\n",
    "Следующая проблема - заголовки у нас последовательности произвольной длины. Возьмем идею энкодера из seq2seq. В классике энкодер представляет собой RNN-блок, который, получив последовательность слов или символов, возвращает некоторый сжатый вектор, который уже декодируется декодером.\n",
    "\n",
    "Длины последовательностей символов заголовков могут быть приличные, а RNN имеет свойство забывать. Поэтому будем использовать LSTM блок.\n",
    "\n",
    "Будем считать, что энкодер закодирует нам эмбеддинг, далее нужно подсказать сети, какие эмбеддинги соответствуют одному товару, а какие разным. Здесь подойдет metric learning. Используем логику работы сиамских сетей и старый-добрый triplet loss (contrasitive loss показал себя хуже).\n",
    "\n",
    "Резюмируем:\n",
    "- *На этапе обучения* разбиваем заголовок на последовательность символов, каждый символ подаем на вход LSTM блоку, скрытое состояние перекидываем следующему блоку, так до тех пор, пока последовательность не закончится. Получаем вектор скрытого состояния, к которому относимся как к эмбеддингу, полученному энкодером. Аналогично получаем эмбеддинги anchor-positive и anchor-negative объектов. Аггрегируем эти эмбеддинги с помощью triplet loss, заставляем их расстояния отличаться на величину отступа (margin). После, кстати, будет логично использовать значение близкое к отступу в качестве порога в адаптивном поиске кластеров.\n",
    "- *На этапе контроля* получаем эмбеддинги обученным энкодером, а затем ищем в пространстве эмбеддингов соседа (1NN) или соседей по порогу (adaptive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tokens encoding***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем биекцию символов в числовые коды (LSTM блок на вход принимает числа), переводим весь наш корпус в эти коды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "f89CFKXcCf-d"
   },
   "outputs": [],
   "source": [
    "def build_corpus_per_word(text_series):\n",
    "    corpus = [\n",
    "        tokens.tolist()\n",
    "        for series in text_series\n",
    "            for tokens in series.values\n",
    "    ]\n",
    "    return corpus\n",
    "\n",
    "def build_corpus_per_char(text_series):\n",
    "    corpus = [\n",
    "        list(\"_\".join(tokens.tolist()))\n",
    "        for series in text_series\n",
    "            for tokens in series.values\n",
    "    ]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "WOftt9ytCf-e"
   },
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    def __init__(self, default_tokens):\n",
    "        self.token2idx = default_tokens\n",
    "        self.token2count = {token: 1 for token in default_tokens}\n",
    "        self.idx2token = {default_tokens[token]: token for token in default_tokens}\n",
    "        self.n_words = len(default_tokens)\n",
    "    \n",
    "    def fit(self, corpus):\n",
    "        self.corpus = corpus\n",
    "        for tokens in corpus:\n",
    "            for token in tokens:\n",
    "                if token in self.token2idx:\n",
    "                    self.token2count[token] += 1\n",
    "                else:\n",
    "                    self.token2idx[token] = self.n_words\n",
    "                    self.token2count[token] = 1\n",
    "                    self.idx2token[self.n_words] = token\n",
    "                    self.n_words += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HSnU6vaCf-e"
   },
   "outputs": [],
   "source": [
    "def transform_chars(batch, corpus):\n",
    "    return [\n",
    "        [corpus.token2idx[char] for char in list(\"_\".join(tokens.tolist()))]\n",
    "        for tokens in batch\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Padding & packing***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучать сеть хотим по батчам. Это и эффективно по времени, и уменьшает смещение стохастического градиента. Здесь следующая трудность: батч состоит из последовательностей кодов символов, но эти последовательности будут разной длины. Решаем проблему забиванием нулями с конца всех последовательностей так, чтобы их длина совпадала с максимальной в батче. \n",
    "\n",
    "Проблема переменных длин в батче аукнется и при генерации батчей даталоадером. В этом случае нужна функция collate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmECTUKXCf-f"
   },
   "outputs": [],
   "source": [
    "def preproc_vect_seq_batch(batch2idx):\n",
    "    # finding max seq len\n",
    "    seq_lens = torch.LongTensor(list(map(len, batch2idx)))\n",
    "    seq_tensor = Variable(torch.zeros((len(batch2idx), seq_lens.max()))).long()\n",
    "    \n",
    "    # filling seqs, padding with zeros\n",
    "    for idx, (seq, seq_len) in enumerate(zip(batch2idx, seq_lens)):\n",
    "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
    "        \n",
    "    # pushing seqs with max zeros amount to the end\n",
    "    seq_lens, perm_idx = seq_lens.sort(0, descending=True)\n",
    "    seq_tensor = seq_tensor[perm_idx]\n",
    "    \n",
    "    return seq_tensor, seq_lens, perm_idx\n",
    "\n",
    "def collate_pad(batch):\n",
    "    batch2idx = [obj[0] for obj in batch]\n",
    "    labels = [obj[1] for obj in batch]\n",
    "    seq_tensor, seq_lens, perm_idx = preproc_vect_seq_batch(batch2idx)\n",
    "    \n",
    "    return seq_tensor.to(DEVICE), seq_lens.to(DEVICE), torch.tensor(labels)[perm_idx].to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Непосредственно энкодер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zjw0KHs_Cf-f"
   },
   "outputs": [],
   "source": [
    "# padding idea from https://gist.github.com/HarshTrivedi/f4e7293e941b17d19058f6fb90ab0fec\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    # N - batch size; L - seq len; H - hidden size; E - embed_size\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size) # num_embeddings, embedding_dim\n",
    "        self.rnn = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        seq_tensor, seq_lens, _ = batch # (N, L); (N, )\n",
    "        embeds = self.embedding(seq_tensor) # (N, L, E)\n",
    "        \n",
    "        packed_input = pack_padded_sequence( # (batch_sum_seq_len, E)\n",
    "            embeds, seq_lens.cpu(), batch_first=True\n",
    "        ) \n",
    "        \n",
    "        _, (hidden, cell) = self.rnn(packed_input) # cell for LSTM\n",
    "        \n",
    "        return hidden[-1] # (N, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналоги построчного усреднения F1 для предсказаний сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpQ6eVzFCf-f"
   },
   "outputs": [],
   "source": [
    "def f1_score_labels_1d(y_true, y_pred):\n",
    "    intersection = set(y_true) & set(y_pred)\n",
    "    return 2 * len(intersection) / (len(y_true) + len(y_pred))\n",
    "\n",
    "def f1_score_labels(y_true, y_pred):\n",
    "    out = []\n",
    "    for i, label in enumerate(y_true):\n",
    "        true_idxs = np.where(y_true == label)[0]\n",
    "        pred_idxs = y_pred[i]\n",
    "        out.append(f1_score_labels_1d(true_idxs, pred_idxs))\n",
    "    return np.mean(np.array(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечное предсказание кластеров - 1NN и перебор порога, а также валидация и обучение. Оцениваемся усредненным построчным F1 на отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RylucSmGCf-g"
   },
   "outputs": [],
   "source": [
    "def predict_1neighbor(X, dists):\n",
    "    # rows of X - coords\n",
    "    # dists - pairwise distances\n",
    "    # returns idx of closest neighbor for every object\n",
    "    dists[np.arange(len(dists)), np.arange(len(dists))] = np.max(dists)\n",
    "    \n",
    "    pred = np.argmin(dists, axis=0)\n",
    "    return np.vstack((np.arange(len(X)), pred)).T\n",
    "\n",
    "def predict_neighbors_adaptive(X, dists, thresh):\n",
    "    # rows of X - coords\n",
    "    # returns idxs of neighbors wrt to threshold for every object\n",
    "    dists[np.arange(len(dists)), np.arange(len(dists))] = np.max(dists)\n",
    "\n",
    "    output = [[i] for i in range(len(X))]\n",
    "    wheres = np.where(dists < thresh)\n",
    "    for i in range(len(wheres[0])):\n",
    "        idx, value = wheres[0][i], wheres[1][i]\n",
    "        if len(output[idx]) < 52: # no more than 51 neighbors in real data\n",
    "            output[idx].append(value)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ACbe9SoCf-g"
   },
   "outputs": [],
   "source": [
    "def validate_model(model, test_loader, X_val_len, y_val, output_label=\"VAL\"):\n",
    "        \n",
    "    pred_val = torch.zeros((X_val_len, HIDDEN_SIZE))\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            _, _, seq_idxs = data\n",
    "            hidden = model(data)\n",
    "            for i, pred_val_i in enumerate(seq_idxs):\n",
    "                pred_val[pred_val_i] = hidden[i]\n",
    "    \n",
    "    X = pred_val.detach().numpy()\n",
    "    start = time.time()\n",
    "    dists = distance_matrix(X, X)\n",
    "    y_pred_1nn = predict_1neighbor(X, dists)\n",
    "    f1_1nn = f1_score_labels(y_val, y_pred_1nn)\n",
    "\n",
    "    f1_adapt_list = []\n",
    "    for thresh in THRESH:\n",
    "        y_pred_adapt = predict_neighbors_adaptive(X, dists, thresh)\n",
    "        f1_adapt = f1_score_labels(y_val, y_pred_adapt)\n",
    "        f1_adapt_list.append(f1_adapt)\n",
    "        \n",
    "    print(f\"{output_label} | 1NN F1: {round(f1_1nn, 4)}\")\n",
    "    print(f\"{output_label} | ADAPT\", end=\"\")\n",
    "    for i in range(len(THRESH)):\n",
    "        print(f\"|TH: {THRESH[i]} F1: {round(f1_adapt_list[i], 4)}\", end=\"\")\n",
    "    print('')\n",
    "    \n",
    "    return f1_1nn, f1_adapt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33Tju2YTCf-h"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, loss_func, train_loader, test_loader, \n",
    "                X_train_len, X_val_len, y_train, y_val, flush_rate=100):\n",
    "    val_output = []\n",
    "    running_loss = 0\n",
    "    batch_losses = []\n",
    "    avg_losses = []\n",
    "    epoch_start = time.time()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # data - (seq, seq_len, label)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(data)\n",
    "        labels = data[-1]\n",
    "        loss = loss_func(embeddings, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_losses.append(loss.item())\n",
    "        running_loss += loss.item() * data[0].shape[0]\n",
    "        \n",
    "        if (i + 1) % flush_rate == 0:\n",
    "            avg_loss = np.array(batch_losses).mean()\n",
    "            avg_losses.append(avg_loss)\n",
    "            print(f\"ITER {i + 1} | AVERAGE LOSS {round(avg_loss, 3)} | RUNNING LOSS {round(running_loss, 3)}\")\n",
    "            val_output.append(validate_model(model, test_loader, X_val_len, y_val, \"TEST\"))\n",
    "            batch_losses = []\n",
    "    running_loss /= len(train_loader)\n",
    "    \n",
    "    print(f\"EPOCH OVER ({round(time.time() - epoch_start, 2)} sec) | AVG LOSS {round(np.array(batch_losses).mean(), 3)} | RAN LOSS {round(running_loss, 3)}\")\n",
    "    validate_model(model, test_loader, X_val_len, y_val, \"TEST\")\n",
    "    \n",
    "    return val_output, avg_losses, running_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Training***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим корпус, переводим в коды, разбиваем на обучение и контроль."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KaaZvl52Cf-h"
   },
   "outputs": [],
   "source": [
    "corpus = Corpus({\"PAD\": 0, \"_\": 1})\n",
    "corpus.fit(build_corpus_per_char([df['text']]))\n",
    "\n",
    "X = transform_chars(df['text'].values, corpus)\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=1337\n",
    ")\n",
    "\n",
    "Xy_train = list(zip(X_train, y_train))\n",
    "Xidx_val = list(zip(X_val, [i for i in range(len(X_val))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем полезные функции из библиотеки pytorch-metric-learning, это\n",
    "- сэмплер - строит батч таким образом, что в нем обязательно есть хотя бы два заголовка одного товара (не должен встретиться объект, для которого не будет anchor-positive)\n",
    "- волшебный triplet loss, который самостоятельно перебирает все подходящие тройки в батче\n",
    "\n",
    "Размерность эмбеддингов (они же скрытые состояния у LSTM) выберем заведомо небольшой, чтобы избежать проклятия размерности.\n",
    "Оптимизируем адамом, без регуляризации. Тюнинг гиперпараметров в данном ноутбуке удалим, и так много получается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9mlfRKDCf-h"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EMBED_SIZE = 64\n",
    "HIDDEN_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0001\n",
    "WEIGHT_DECAY = 0\n",
    "THRESH = [0.01, 0.05, 0.1, 0.15, 0.2]\n",
    "\n",
    "sampler = samplers.MPerClassSampler(labels=y_train, m=2, batch_size=BATCH_SIZE, length_before_new_iter=100000)\n",
    "# reducer = reducers.MeanReducer()\n",
    "train_loader = DataLoader(dataset=Xy_train, sampler=sampler, batch_size=BATCH_SIZE, collate_fn=collate_pad)\n",
    "test_loader = DataLoader(dataset=Xidx_val, batch_size=BATCH_SIZE, collate_fn=collate_pad)\n",
    "model = Encoder(\n",
    "    vocab_size=corpus.n_words,\n",
    "    embed_size=EMBED_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE\n",
    ").to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "loss_func = losses.TripletMarginLoss(margin=0.1,\n",
    "                        swap=False,\n",
    "                        smooth_loss=False,\n",
    "                        triplets_per_anchor=\"all\")\n",
    "#loss_func = losses.ContrastiveLoss(pos_margin=0, neg_margin=, reducer=reducer) # eucl dist by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8O3Gv-ZnCf-i",
    "outputId": "9ae9078e-2beb-472d-ff2a-66f7d195bd8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 START\n",
      "ITER 1000 | AVERAGE LOSS 0.123 | RUNNING LOSS 3949.582\n",
      "TEST | 1NN F1: 0.5541\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.189|TH: 0.05 F1: 0.0994|TH: 0.1 F1: 0.0805|TH: 0.15 F1: 0.0735|TH: 0.2 F1: 0.0696\n",
      "ITER 2000 | AVERAGE LOSS 0.11 | RUNNING LOSS 7477.237\n",
      "TEST | 1NN F1: 0.555\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.5579|TH: 0.05 F1: 0.1451|TH: 0.1 F1: 0.0884|TH: 0.15 F1: 0.0749|TH: 0.2 F1: 0.0681\n",
      "ITER 3000 | AVERAGE LOSS 0.105 | RUNNING LOSS 10851.002\n",
      "TEST | 1NN F1: 0.5552\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.6134|TH: 0.05 F1: 0.1673|TH: 0.1 F1: 0.096|TH: 0.15 F1: 0.0775|TH: 0.2 F1: 0.0703\n",
      "EPOCH OVER (134.73 sec) | AVG LOSS 0.102 | RAN LOSS 3.603\n",
      "TEST | 1NN F1: 0.5568\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.6975|TH: 0.05 F1: 0.2098|TH: 0.1 F1: 0.1035|TH: 0.15 F1: 0.0792|TH: 0.2 F1: 0.0702\n",
      "EPOCH 1 START\n",
      "ITER 1000 | AVERAGE LOSS 0.103 | RUNNING LOSS 3306.878\n",
      "TEST | 1NN F1: 0.5569\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7493|TH: 0.05 F1: 0.2878|TH: 0.1 F1: 0.128|TH: 0.15 F1: 0.0912|TH: 0.2 F1: 0.0749\n",
      "ITER 2000 | AVERAGE LOSS 0.102 | RUNNING LOSS 6562.135\n",
      "TEST | 1NN F1: 0.5569\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7877|TH: 0.05 F1: 0.6045|TH: 0.1 F1: 0.2916|TH: 0.15 F1: 0.154|TH: 0.2 F1: 0.0995\n",
      "ITER 3000 | AVERAGE LOSS 0.097 | RUNNING LOSS 9679.346\n",
      "TEST | 1NN F1: 0.558\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7894|TH: 0.05 F1: 0.7018|TH: 0.1 F1: 0.4041|TH: 0.15 F1: 0.2055|TH: 0.2 F1: 0.1209\n",
      "EPOCH OVER (127.49 sec) | AVG LOSS 0.093 | RAN LOSS 3.217\n",
      "TEST | 1NN F1: 0.5583\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7893|TH: 0.05 F1: 0.7031|TH: 0.1 F1: 0.4145|TH: 0.15 F1: 0.2216|TH: 0.2 F1: 0.1315\n",
      "EPOCH 2 START\n",
      "ITER 1000 | AVERAGE LOSS 0.095 | RUNNING LOSS 3055.666\n",
      "TEST | 1NN F1: 0.5604\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.79|TH: 0.05 F1: 0.7342|TH: 0.1 F1: 0.47|TH: 0.15 F1: 0.2488|TH: 0.2 F1: 0.1437\n",
      "ITER 2000 | AVERAGE LOSS 0.096 | RUNNING LOSS 6123.709\n",
      "TEST | 1NN F1: 0.5603\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7898|TH: 0.05 F1: 0.7735|TH: 0.1 F1: 0.5897|TH: 0.15 F1: 0.3278|TH: 0.2 F1: 0.1798\n",
      "ITER 3000 | AVERAGE LOSS 0.096 | RUNNING LOSS 9190.818\n",
      "TEST | 1NN F1: 0.5613\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7901|TH: 0.05 F1: 0.776|TH: 0.1 F1: 0.6256|TH: 0.15 F1: 0.3793|TH: 0.2 F1: 0.2137\n",
      "EPOCH OVER (125.92 sec) | AVG LOSS 0.096 | RAN LOSS 3.064\n",
      "TEST | 1NN F1: 0.5625\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7723|TH: 0.1 F1: 0.6067|TH: 0.15 F1: 0.3506|TH: 0.2 F1: 0.1981\n",
      "EPOCH 3 START\n",
      "ITER 1000 | AVERAGE LOSS 0.095 | RUNNING LOSS 3054.366\n",
      "TEST | 1NN F1: 0.5664\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7906|TH: 0.05 F1: 0.7862|TH: 0.1 F1: 0.7083|TH: 0.15 F1: 0.5201|TH: 0.2 F1: 0.3303\n",
      "ITER 2000 | AVERAGE LOSS 0.095 | RUNNING LOSS 6105.369\n",
      "TEST | 1NN F1: 0.566\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7901|TH: 0.05 F1: 0.7895|TH: 0.1 F1: 0.7457|TH: 0.15 F1: 0.6065|TH: 0.2 F1: 0.4251\n",
      "ITER 3000 | AVERAGE LOSS 0.093 | RUNNING LOSS 9095.448\n",
      "TEST | 1NN F1: 0.57\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7907|TH: 0.05 F1: 0.7914|TH: 0.1 F1: 0.7583|TH: 0.15 F1: 0.6472|TH: 0.2 F1: 0.4747\n",
      "EPOCH OVER (126.66 sec) | AVG LOSS 0.093 | RAN LOSS 3.029\n",
      "TEST | 1NN F1: 0.5688\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7903|TH: 0.05 F1: 0.7914|TH: 0.1 F1: 0.7615|TH: 0.15 F1: 0.6538|TH: 0.2 F1: 0.4825\n",
      "EPOCH 4 START\n",
      "ITER 1000 | AVERAGE LOSS 0.094 | RUNNING LOSS 3011.6\n",
      "TEST | 1NN F1: 0.5711\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.791|TH: 0.05 F1: 0.792|TH: 0.1 F1: 0.7622|TH: 0.15 F1: 0.6488|TH: 0.2 F1: 0.4827\n",
      "ITER 2000 | AVERAGE LOSS 0.094 | RUNNING LOSS 6004.255\n",
      "TEST | 1NN F1: 0.5713\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7907|TH: 0.05 F1: 0.7931|TH: 0.1 F1: 0.7738|TH: 0.15 F1: 0.6807|TH: 0.2 F1: 0.5258\n",
      "ITER 3000 | AVERAGE LOSS 0.095 | RUNNING LOSS 9038.179\n",
      "TEST | 1NN F1: 0.5719\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7901|TH: 0.05 F1: 0.7922|TH: 0.1 F1: 0.7871|TH: 0.15 F1: 0.7523|TH: 0.2 F1: 0.649\n",
      "EPOCH OVER (125.89 sec) | AVG LOSS 0.095 | RAN LOSS 3.014\n",
      "TEST | 1NN F1: 0.5719\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7919|TH: 0.1 F1: 0.786|TH: 0.15 F1: 0.7504|TH: 0.2 F1: 0.6631\n",
      "EPOCH 5 START\n",
      "ITER 1000 | AVERAGE LOSS 0.094 | RUNNING LOSS 2992.282\n",
      "TEST | 1NN F1: 0.5711\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7913|TH: 0.1 F1: 0.7893|TH: 0.15 F1: 0.7629|TH: 0.2 F1: 0.6743\n",
      "ITER 2000 | AVERAGE LOSS 0.095 | RUNNING LOSS 6030.292\n",
      "TEST | 1NN F1: 0.5709\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7912|TH: 0.1 F1: 0.787|TH: 0.15 F1: 0.7529|TH: 0.2 F1: 0.6672\n",
      "ITER 3000 | AVERAGE LOSS 0.093 | RUNNING LOSS 9017.971\n",
      "TEST | 1NN F1: 0.5725\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7901|TH: 0.05 F1: 0.7919|TH: 0.1 F1: 0.788|TH: 0.15 F1: 0.7557|TH: 0.2 F1: 0.671\n",
      "EPOCH OVER (125.08 sec) | AVG LOSS 0.094 | RAN LOSS 3.007\n",
      "TEST | 1NN F1: 0.5727\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7916|TH: 0.1 F1: 0.7892|TH: 0.15 F1: 0.756|TH: 0.2 F1: 0.6668\n",
      "EPOCH 6 START\n",
      "ITER 1000 | AVERAGE LOSS 0.095 | RUNNING LOSS 3027.169\n",
      "TEST | 1NN F1: 0.5734\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7913|TH: 0.1 F1: 0.789|TH: 0.15 F1: 0.7601|TH: 0.2 F1: 0.6692\n",
      "ITER 2000 | AVERAGE LOSS 0.094 | RUNNING LOSS 6026.269\n",
      "TEST | 1NN F1: 0.5712\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7925|TH: 0.1 F1: 0.7861|TH: 0.15 F1: 0.7387|TH: 0.2 F1: 0.6266\n",
      "ITER 3000 | AVERAGE LOSS 0.094 | RUNNING LOSS 9045.329\n",
      "TEST | 1NN F1: 0.5723\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7901|TH: 0.05 F1: 0.792|TH: 0.1 F1: 0.79|TH: 0.15 F1: 0.7618|TH: 0.2 F1: 0.6761\n",
      "EPOCH OVER (125.66 sec) | AVG LOSS 0.093 | RAN LOSS 3.013\n",
      "TEST | 1NN F1: 0.5717\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7916|TH: 0.1 F1: 0.7898|TH: 0.15 F1: 0.7633|TH: 0.2 F1: 0.6807\n",
      "EPOCH 7 START\n",
      "ITER 1000 | AVERAGE LOSS 0.095 | RUNNING LOSS 3027.15\n",
      "TEST | 1NN F1: 0.5718\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7913|TH: 0.1 F1: 0.7897|TH: 0.15 F1: 0.7634|TH: 0.2 F1: 0.6842\n",
      "ITER 2000 | AVERAGE LOSS 0.095 | RUNNING LOSS 6054.08\n",
      "TEST | 1NN F1: 0.5727\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7917|TH: 0.1 F1: 0.791|TH: 0.15 F1: 0.7602|TH: 0.2 F1: 0.668\n",
      "ITER 3000 | AVERAGE LOSS 0.095 | RUNNING LOSS 9094.436\n",
      "TEST | 1NN F1: 0.573\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7922|TH: 0.1 F1: 0.7886|TH: 0.15 F1: 0.7576|TH: 0.2 F1: 0.6719\n",
      "EPOCH OVER (125.29 sec) | AVG LOSS 0.094 | RAN LOSS 3.031\n",
      "TEST | 1NN F1: 0.5731\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7921|TH: 0.1 F1: 0.7897|TH: 0.15 F1: 0.7559|TH: 0.2 F1: 0.6588\n",
      "EPOCH 8 START\n",
      "ITER 1000 | AVERAGE LOSS 0.096 | RUNNING LOSS 3067.995\n",
      "TEST | 1NN F1: 0.5717\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7916|TH: 0.1 F1: 0.7887|TH: 0.15 F1: 0.7585|TH: 0.2 F1: 0.667\n",
      "ITER 2000 | AVERAGE LOSS 0.095 | RUNNING LOSS 6122.815\n",
      "TEST | 1NN F1: 0.5718\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7913|TH: 0.1 F1: 0.7884|TH: 0.15 F1: 0.762|TH: 0.2 F1: 0.6729\n",
      "ITER 3000 | AVERAGE LOSS 0.095 | RUNNING LOSS 9169.93\n",
      "TEST | 1NN F1: 0.5719\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7913|TH: 0.1 F1: 0.7902|TH: 0.15 F1: 0.7569|TH: 0.2 F1: 0.6655\n",
      "EPOCH OVER (125.45 sec) | AVG LOSS 0.092 | RAN LOSS 3.052\n",
      "TEST | 1NN F1: 0.573\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7917|TH: 0.1 F1: 0.7892|TH: 0.15 F1: 0.7562|TH: 0.2 F1: 0.6642\n",
      "EPOCH 9 START\n",
      "ITER 1000 | AVERAGE LOSS 0.095 | RUNNING LOSS 3053.048\n",
      "TEST | 1NN F1: 0.5734\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7915|TH: 0.1 F1: 0.7912|TH: 0.15 F1: 0.7743|TH: 0.2 F1: 0.7118\n",
      "ITER 2000 | AVERAGE LOSS 0.095 | RUNNING LOSS 6096.118\n",
      "TEST | 1NN F1: 0.5736\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7916|TH: 0.1 F1: 0.7913|TH: 0.15 F1: 0.7726|TH: 0.2 F1: 0.7058\n",
      "ITER 3000 | AVERAGE LOSS 0.093 | RUNNING LOSS 9066.435\n",
      "TEST | 1NN F1: 0.5761\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7919|TH: 0.1 F1: 0.7932|TH: 0.15 F1: 0.7863|TH: 0.2 F1: 0.7499\n",
      "EPOCH OVER (125.18 sec) | AVG LOSS 0.093 | RAN LOSS 3.021\n",
      "TEST | 1NN F1: 0.5767\n",
      "TEST | ADAPT|TH: 0.01 F1: 0.7899|TH: 0.05 F1: 0.7918|TH: 0.1 F1: 0.7928|TH: 0.15 F1: 0.7854|TH: 0.2 F1: 0.7427\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "\n",
    "output = {}\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"EPOCH {epoch} START\")\n",
    "    out = train_epoch(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss_func=loss_func,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        X_train_len=len(X_train),\n",
    "        X_val_len=len(X_val),\n",
    "        y_train=y_train,\n",
    "        y_val=y_val ,\n",
    "        flush_rate=1000\n",
    "    )   \n",
    "    output[epoch] = out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Качество 1NN на контроле ~0.58** после 10 эпох (близко к 1NN на tf-idf).\n",
    "\n",
    "**Качество adaptive neighbors ~0.79**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим динамику лосса и качества F1 с течением эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "2xpdR4idl23j",
    "outputId": "b1ad63d0-d475-4adb-9714-8ec1342a26e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=list(output.keys()), y=[output[epoch][-1] for epoch in output])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "gcHC8c0LnOKk",
    "outputId": "3b7e12b0-f7c5-4425-e3d0-6aa6a27125c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'F1')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdVklEQVR4nO3dfXRcd33n8fd3NJZkybYsx3LsWLalJM6DE5s4kRUgSzeQhDqUJhTCrk3DgWzbnN0SmgLdkPAQqLtLC9mFXU7dLoFCYZsSgkOoCy7mKXCgCx7JwbEjO06MR478UCRrbPlB1tPMd/+YkTySZVuOdXVn5n5e5/jo3t/9zZ2vJ9H9zP39fO81d0dERKIrFnYBIiISLgWBiEjEKQhERCJOQSAiEnEKAhGRiIuHXcCFmjt3rjc0NIRdhohIUdm6dethd68bb1vRBUFDQwOtra1hlyEiUlTMbN/ZtmloSEQk4hQEIiIRpyAQEYm4QIPAzFab2W4z22NmD4+zfbGZPWtmvzKz7Wb2liDrERGRMwUWBGZWBqwH7gSWAWvNbNmYbh8DnnL3lcAa4G+CqkdERMYX5BlBM7DH3fe6+wDwJHD3mD4OzMot1wAHA6xHRETGEWQQLAQ68tb359ryfRK418z2A5uA94+3IzO738xazay1q6sriFpFRCIr7OsI1gJ/7+7/08xeB/xfM7ve3TP5ndz9ceBxgKamJt03W8Y1mM7QP5ShfzBN3/DPwQz9Q2n6hzL0DWZ/jlrOayszI15mxGNGWcyYVhbL/TTKYrHcTyOetzy2Tzw2vI9x+sRilOX2P/weZnZBf0d3J51x0u5kMpDOrWdG2jyvLW/78OvylrM/Gb09tw93MIOYGWZgZsSG1zm9nv9zuH/MwLBRrx9pH3lNdj+n9z+6r+XtY/j9sj+z7Qzva5xtwx/pOfdxgZ97EIYfATD8JADPaz+9PLwtuxCPZf9fmmxBBsEBYFHeen2uLd8fAKsB3P0XZlYJzAU6A6xLQubuHD4xQHv3SfZ193K8b3D8A/Zghr6hNP3D23I/z3ZwT2eK7zvCSFjkhcTpAzajDs5pd/T4kMl1zqDJX+f0wXjsgRs/+7aRg/3I+sXV+9/edj33vnbJxe1kHEEGQQuw1MwayQbAGuBdY/q8AtwG/L2ZXQtUAhr7KQHuzpHeQZKHT9J++CTt3Sezy90naT/cy4n+oXFfN63MqIyXUTEtRkXez8ppMSriMWZXleeWy6iIx6icNvpnxbRx2vL3N/Y1uf2Wl8Vwh8FMNlAG09mD8VA6w1DGGUo7Q5ns8mD6LH0ymVy/032G109vy9vfyOtO7z+dcWKWDYfsT4jFjLJRbWO2n9GW7R+Ljdk+3Da8r5E2zmgzyx60HMi4Z7+lOmR8eD373ziTOwgOt5P7mcnfnvuGm9/uefsZ2V/efjzvdWcsM/rbtON57afXh/8/HG+b5148XvvwOnnvNXwGMfJdfPisI7cwHCjDy2O3jX6tTajv6TOb02cANyyaffZfuosQWBC4+5CZPQBsBsqAL7t7m5mtA1rdfSPwIeCLZvYBsp/5e12PTCsqR3sHRg7wycO9Iwf99sMnOdZ3+mAfM6ivraJhbjU3La6lYW519s8l1cyePm3kQB3Eae9EmUFFrCy09xcJixXbcbepqcl1r6GpdaxvkPbDuW/0h3tHfbs/2js40s8MFs6eTmPuAL/kkqrs8txqFtVWUR7X9YsiYTGzre7eNN62sCeLpUCc6B/KO9ifJJn7Vr+vu5fukwOj+l5WU0nD3GresnwBjZdkD/SNc6tYNKeKiri+UYsUGwVBRD37YiebdhwaGdI5fKJ/1Pb5syppmFvFm6+7lIaRg301i+dUUTlNB3uRUqIgiKBdh47xR19rZdb0aVw5bwa3XTMvN15fNTJuP71cB3uRqFAQRMxQOsNDG7ZTM30aP/jgv2dOdXnYJYlIyBQEEfPFnyXZcaCH9e+6USEgIoBuQx0pv+46wed++BKrr5vPW5bPD7scESkQCoKISGechzZsZ/q0Mta97bqCuMReRAqDgiAivvaLdrbuO8InfncZ82ZWhl2OiBQQBUEEvNLdy2e+t5s3Xl3H760cewNYEYk6BUGJc3c+/PR24jHjU29friEhETmDgqDEfT3RwS/2dvPIW65lQc30sMsRkQKkIChhB4+e4lObdvH6Ky5hbfOi879ARCJJQVCi3J2PPLODdMb5q7ev0JCQiJyVgqBEfeu5A/xkdxcPrb6axZdUhV2OiBQwBUEJ6jzex7rv7KRpSS3veV1D2OWISIFTEJQYd+fj336BU4NpPn3PCmIhPuhFRIqDgqDEbNrxb2xu+w0fvOMqrqibEXY5IlIEFAQlJHVygEf/6QVW1Nfwh/+uMexyRKRI6O6jJeTP/7mNY32DPHHPzcTLlPEiMjE6WpSIH+z8Df+07SDve+OVXDN/VtjliEgRURCUgJ5Tg3z0mR1cM38mf3zrlWGXIyJFJtAgMLPVZrbbzPaY2cPjbP+cmW3L/XnJzI4GWU+p+tR3d9F9coDH7nkN5XFlu4hcmMDmCMysDFgP3AHsB1rMbKO77xzu4+4fyOv/fmBlUPWUqp+93MU3Wjv4L7dewfL6mrDLEZEiFOTXx2Zgj7vvdfcB4Eng7nP0Xwt8PcB6Ss6J/iEefnoHl9dV8+BtS8MuR0SKVJBBsBDoyFvfn2s7g5ktARqBHwdYT8n5zPde5GDPKR67ZwWV08rCLkdEilShDCivATa4e3q8jWZ2v5m1mllrV1fXFJdWmLbs7eZrv9jHfa9v5KYlc8IuR0SKWJBBcADIv/dxfa5tPGs4x7CQuz/u7k3u3lRXVzeJJRanUwNpPvz0dhbPqeLPfvuqsMsRkSIXZBC0AEvNrNHMyske7DeO7WRm1wC1wC8CrKWkfPYHu2nv7uWv3rGcqnJdEygiFyewIHD3IeABYDOwC3jK3dvMbJ2Z3ZXXdQ3wpLt7ULWUkl+9coS/+3mSd928mNdfMTfsckSkBAT6ddLdNwGbxrQ9Omb9k0HWUEr6h9I8tGE7l86q5JE7rwm7HBEpERpXKCJ//eM9vNx5gq/ct4qZldPCLkdESkSh/KshOY8XDvTwNz/5Ne+4sZ43Xj0v7HJEpIQoCIrAYDrDQxu2M6e6nI+/9dqwyxGREqOhoSLwhZ/+mp2HjvGFd9/E7KrysMsRkRKjM4IC99JvjvP5H+3hrSsW8NvXzQ+7HBEpQQqCApbOOA9t2M6Myjh/ftd1YZcjIiVKQ0MF7Cv/mmRbx1E+v3Yll8yoCLscESlROiMoUMnDJ3ls825uv/ZSfnfFgrDLEZESpiAoQJmM8+Gnt1Mej/Hff+96zCzskkSkhCkICtATW/aRSKb4+FuXcemsyrDLEZESpyAoMB2pXv7yX17kDUvn8s6b6sMuR0QiQEFQQNydjzyzAwP+8u3LNSQkIlNCQVBAvtm6n5+9fJiH33It9bVVYZcjIhGhICgQvznWx198dyc3N87h95sXh12OiESIgqAAuDsffWYHg+kMn37HCmIxDQmJyNRREBSAjc8f5Ie7OvmzN19Nw9zqsMsRkYhREITs8Il+PrmxjZWLZ3PfLY1hlyMiEaQgCNknNrZxsj/NY/esoExDQiISAgVBiL73wiG+u/0QD96+lCvnzQy7HBGJKAVBSI72DvCxb7dx3WWzuP+3Lg+7HBGJMN19NCTrvrOTo70DfPU/rWJamfJYRMKjI1AInn2xk289d4A/vvUKrrusJuxyRCTiAg0CM1ttZrvNbI+ZPXyWPv/BzHaaWZuZ/WOQ9RSC432DfOSZHVx16Qze96Yrwy5HRCS4oSEzKwPWA3cA+4EWM9vo7jvz+iwFHgFucfcjZjYvqHoKxV//eA+/OdbH3957CxXxsrDLEREJ9IygGdjj7nvdfQB4Erh7TJ8/Ata7+xEAd+8MsJ6C8OMXO3nD0jpuWDQ77FJERIBgg2Ah0JG3vj/Xlu8q4Coz+1cz+6WZrR5vR2Z2v5m1mllrV1dXQOUGr/tEPy93nuDmy+eEXYqIyIiwJ4vjwFLgVmAt8EUzO+Orsrs/7u5N7t5UV1c3xSVOnpb2IwDc3KggEJHCEWQQHAAW5a3X59ry7Qc2uvuguyeBl8gGQ0lKJFNUxGMsX6hhIREpHEEGQQuw1MwazawcWANsHNPn22TPBjCzuWSHivYGWFOoWtpT3Li4lvJ42CdiIiKnBXZEcvch4AFgM7ALeMrd28xsnZndleu2Geg2s53As8B/dffuoGoK0/G+QdoO9rBKw0IiUmACvbLY3TcBm8a0PZq37MAHc39K2tZ9R8i45gdEpPBojGKKJJIp4jFj5WLND4hIYVEQTJGW9hTL62uoKtftnUSksCgIpkDfYJrnO3po1rCQiBQgBcEU2NZxlIF0huYGBYGIFB4FwRRIJFOYQdMSBYGIFB4FwRRIJFNcM38WNVXTwi5FROQMCoKADaYzPPfKEf2zUREpWAqCgLUdPEbvQJpVmh8QkQKlIAhYIpm9UHpVY23IlYiIjE9BELBEMsXlc6uZN7My7FJERMalIAhQJuO0tB/R9QMiUtAUBAF6qfM4PacGFQQiUtAUBAFKJFMAmigWkYKmIAjQlmSKy2oqqa+dHnYpIiJnpSAIiLuTSKZobpyDmYVdjojIWSkIArKvu5eu4/00N14SdikiIuekIAjI8PxAs64fEJECpyAIyJZkijnV5VxRNyPsUkREzklBEJBEezfNDZofEJHCpyAIwKGeU3SkTun6AREpCgqCAJyeH1AQiEjhCzQIzGy1me02sz1m9vA4299rZl1mti335w+DrGeqJJIpZlbEuXbBrLBLERE5r8CepG5mZcB64A5gP9BiZhvdfeeYrt9w9weCqiMMiWSKmxpqKYtpfkBECl+QZwTNwB533+vuA8CTwN0Bvl9B6D7Rz8udJzQsJCJFI8ggWAh05K3vz7WN9Q4z225mG8xsUYD1TImW9iMAeiKZiBSNsCeL/xlocPcVwA+Ar47XyczuN7NWM2vt6uqa0gIvVEt7iop4jOULZ4ddiojIhAQZBAeA/G/49bm2Ee7e7e79udUvATeNtyN3f9zdm9y9qa6uLpBiJ0simWLl4tmUx8POWBGRiQnyaNUCLDWzRjMrB9YAG/M7mNmCvNW7gF0B1hO4432DtB3s0f2FRKSoBPavhtx9yMweADYDZcCX3b3NzNYBre6+EfgTM7sLGAJSwHuDqmcqbN13hIxrfkBEiktgQQDg7puATWPaHs1bfgR4JMgaplIimSIeM1Yu1vyAiBQPDWRPopb2FNcvrKGqPNB8FRGZVK86CMzsmskspNj1DaZ5vqNHw0IiUnQu5ozg+5NWRQnY1nGUgXRGF5KJSNE55xiGmX3+bJsADYTnSSRTmEHTEgWBiBSX8w1m3wd8COgfZ9vayS+neLW0p7j60pnUVE0LuxQRkQtyviBoAV5w9/83doOZfTKQiorQYDrD1n1HeOdN9WGXIiJywc4XBPcAfeNtcPfGyS+nOLUdPEbvQFoXkolIUTrfZPEMd++dkkqKWCLZDcAqPaheRIrQ+YLg28MLZvZ0wLUUrUQyxeVzq5k3szLsUkRELtj5giD/ySqXB1lIscpknJb2I6xq0L8WEpHidL4g8LMsS85LncfpOTWo6wdEpGidb7L4NWZ2jOyZwfTcMrl1d/fIP5RXD6oXkWJ3ziBw97KpKqRYbUmmuKymkvra6WGXIiLyquimcxfB3UkkU6xqnIOZHlQvIsVJQXAR9nX30nW8X8NCIlLUFAQXYXh+QHccFZFipiC4CFuSKeZUl3NF3YywSxERedUUBBch0d5Nc4PmB0SkuCkIXqVDPafoSJ1ilYaFRKTIKQheJc0PiEipUBC8SolkihkVca5dEPlr6kSkyCkIXqVEMkVTQy1lMc0PiEhxCzQIzGy1me02sz1m9vA5+r3DzNzMmoKsZ7KkTg7wcucJ3WhOREpCYEFgZmXAeuBOYBmw1syWjdNvJvAgsCWoWiZbS7vmB0SkdAR5RtAM7HH3ve4+ADwJ3D1Ov78APs1ZnoRWiBLJFBXxGMvra8IuRUTkogUZBAuBjrz1/bm2EWZ2I7DI3b97rh2Z2f1m1mpmrV1dXZNf6QVKJFOsXDybirjuyScixS+0yWIziwGfBT50vr7u/ri7N7l7U11dXfDFncPxvkHaDvbo+cQiUjKCDIIDwKK89fpc27CZwPXAT8ysHXgtsLHQJ4y37jtCxqFZE8UiUiKCDIIWYKmZNZpZObAG2Di80d173H2uuze4ewPwS+Aud28NsKaL1tKeIh4zblwyO+xSREQmRWBB4O5DwAPAZmAX8JS7t5nZOjO7K6j3DVoimeL6hTVUlZ/v4W4iIsUh0KOZu28CNo1pe/QsfW8NspbJ0DeY5vmOHu67pSHsUkREJo2uLL4A2zqOMpDO6EIyESkpCoILkEimMENBICIlRUFwAVraU1x96UxqqqaFXYqIyKRREEzQYDrD1n1HdFsJESk5CoIJajt4jN6BtC4kE5GSoyCYoESyG4BVjbUhVyIiMrkUBBOUSB6hcW4182ZWhl2KiMikUhBMQCbjtLSndFsJESlJCoIJeKnzOD2nBmnWRLGIlCAFwQQMP6heQSAipUhBMAFbkikW1FRSXzs97FJERCadguA83J2WZIrmxjmY6UH1IlJ6FATnsa+7l87j/RoWEpGSpSA4j+H5AV1RLCKlSkFwHluSKeZUl3NF3YywSxERCYSC4DwS7d2saqjV/ICIlCwFwTkc6jlFR+qU7i8kIiVNQXAOmh8QkShQEJxDIpliRkWcaxfMCrsUEZHAKAjOIZFMcdOSWspimh8QkdKlIDiL1MkBXu48oesHRKTkKQjOoqVd8wMiEg2BBoGZrTaz3Wa2x8weHmf7fzazHWa2zcx+bmbLgqznQiSSKSriMZbX14RdiohIoAILAjMrA9YDdwLLgLXjHOj/0d2Xu/sNwGeAzwZVz4VKJFPcsGg2FfGysEsREQlUkGcEzcAed9/r7gPAk8Dd+R3c/VjeajXgAdYzYcf7Bmk72KNhIRGJhHiA+14IdOSt7wduHtvJzN4HfBAoB9403o7M7H7gfoDFixdPeqFjPffKUTKOLiQTkUgIfbLY3de7+xXAh4GPnaXP4+7e5O5NdXV1gdeUSHYTjxk3Lpkd+HuJiIQtyCA4ACzKW6/PtZ3Nk8DbAqxnwhLJFNcvrKGqPMgTJhGRwhBkELQAS82s0czKgTXAxvwOZrY0b/V3gJcDrGdC+gbTPN/Ro+sHRCQyAvvK6+5DZvYAsBkoA77s7m1mtg5odfeNwANmdjswCBwB3hNUPRO1reMoA+kMzQ0KAhGJhkDHPtx9E7BpTNujecsPBvn+r0ZLMoUZrFIQiEhEhD5ZXGgS7SmuvnQmNVXTwi5FRGRKKAjyDKYzbN13RPMDIhIpCoI8bQeP0TuQVhCISKQoCPIkkt0AmigWkUhREORJJI/QOLeaebMqwy5FRGTKKAhyMhmnpT2lswERiRwFQc5LncfpOTXIKs0PiEjEKAhy9KB6EYkqBUHOlmSKBTWV1NdOD7sUEZEppSAA3J2WZIrmxjmY6UH1IhItCgJgX3cvncf7dVsJEYkkBQGaHxCRaFMQkJ0fmFNdzpXzZoRdiojIlFMQAC3tKVY11Gp+QEQiKfJBcKjnFK+kevV8YhGJrMgHwfD8gK4oFpGoUhAkU8yoiHPtgplhlyIiEgoFQTLFTUtqiZdF/qMQkYiK9NEvdXKAlztP6PkDIhJpkQ6Clvbc/ICCQEQiLNJBkEimKI/HWFFfE3YpIiKhCTQIzGy1me02sz1m9vA42z9oZjvNbLuZ/cjMlgRZz1iJZIqVi2ZTES+byrcVESkogQWBmZUB64E7gWXAWjNbNqbbr4Amd18BbAA+E1Q9Yx3vG6TtYI9uKyEikRfkGUEzsMfd97r7APAkcHd+B3d/1t17c6u/BOoDrGeU5145SsbRhWQiEnlBBsFCoCNvfX+u7Wz+APiX8TaY2f1m1mpmrV1dXZNSXCLZTVnMWLl49qTsT0SkWBXEZLGZ3Qs0AY+Nt93dH3f3Jndvqqurm5T3TCRTXL+whuqK+KTsT0SkWAUZBAeARXnr9bm2UczsduCjwF3u3h9gPSP6BtM836H5ARERCDYIWoClZtZoZuXAGmBjfgczWwl8gWwIdAZYyyjPdxxlIJ3R/YVERAgwCNx9CHgA2AzsAp5y9zYzW2dmd+W6PQbMAL5pZtvMbONZdjephm8019RQOxVvJyJS0AIdIHf3TcCmMW2P5i3fHuT7n02iPcU182cyu6o8jLcXESkoBTFZPJUG0xm27jui20qIiORELgjaDh6jdyCtIBARyYlcELToQTQiIqNELgi2JFM0XFLFvFmVYZciIlIQIhUEmYzT0p7SsJCISJ5IBcFLncfpOTWo+wuJiOSJVBAMXz+gK4pFRE6LXBDMn1VJfe30sEsRESkYkQkCdyeRzM4PmFnY5YiIFIzIBMG+7l46j/drolhEZIzIBIHmB0RExheZIJhdNY07ll3KlfNmhF2KiEhBicxTWd583XzefN38sMsQESk4kTkjEBGR8SkIREQiTkEgIhJxCgIRkYhTEIiIRJyCQEQk4hQEIiIRpyAQEYk4c/ewa7ggZtYF7HuVL58LHJ7EcoqdPo/R9Hmcps9itFL4PJa4e914G4ouCC6GmbW6e1PYdRQKfR6j6fM4TZ/FaKX+eWhoSEQk4hQEIiIRF7UgeDzsAgqMPo/R9Hmcps9itJL+PCI1RyAiImeK2hmBiIiMoSAQEYm4yASBma02s91mtsfMHg67nrCY2SIze9bMdppZm5k9GHZNhcDMyszsV2b2nbBrCZuZzTazDWb2opntMrPXhV1TWMzsA7nfkxfM7OtmVhl2TUGIRBCYWRmwHrgTWAasNbNl4VYVmiHgQ+6+DHgt8L4Ifxb5HgR2hV1EgfjfwPfc/RrgNUT0czGzhcCfAE3ufj1QBqwJt6pgRCIIgGZgj7vvdfcB4Eng7pBrCoW7H3L353LLx8n+ki8Mt6pwmVk98DvAl8KuJWxmVgP8FvB3AO4+4O5Hw60qVHFgupnFgSrgYMj1BCIqQbAQ6Mhb30/ED34AZtYArAS2hFtJ6P4X8BCQCbuQAtAIdAFfyQ2VfcnMqsMuKgzufgD4H8ArwCGgx92/H25VwYhKEMgYZjYDeBr4U3c/FnY9YTGztwKd7r417FoKRBy4Efhbd18JnAQiOadmZrVkRw4agcuAajO7N9yqghGVIDgALMpbr8+1RZKZTSMbAk+4+7fCridktwB3mVk72SHDN5nZP4RbUqj2A/vdffgscQPZYIii24Gku3e5+yDwLeD1IdcUiKgEQQuw1Mwazayc7ITPxpBrCoWZGdnx313u/tmw6wmbuz/i7vXu3kD2/4sfu3tJfuubCHf/N6DDzK7ONd0G7AyxpDC9ArzWzKpyvze3UaIT5/GwC5gK7j5kZg8Am8nO/H/Z3dtCLisstwDvBnaY2bZc20fcfVOINUlheT/wRO5L017gvpDrCYW7bzGzDcBzZP+13a8o0VtN6BYTIiIRF5WhIREROQsFgYhIxCkIREQiTkEgIhJxCgIRkYhTEIhMITO7VXc4lUKjIBARiTgFgcg4zOxeM0uY2TYz+0LueQUnzOxzufvT/8jM6nJ9bzCzX5rZdjN7JnePGszsSjP7oZk9b2bPmdkVud3PyLvf/xO5q1ZFQqMgEBnDzK4F/iNwi7vfAKSB3weqgVZ3vw74KfCJ3Eu+BnzY3VcAO/LanwDWu/tryN6j5lCufSXwp2SfjXE52au9RUITiVtMiFyg24CbgJbcl/XpQCfZ21R/I9fnH4Bv5e7fP9vdf5pr/yrwTTObCSx092cA3L0PILe/hLvvz61vAxqAnwf/1xIZn4JA5EwGfNXdHxnVaPbxMf1e7f1Z+vOW0+j3UEKmoSGRM/0IuMfM5gGY2RwzW0L29+WeXJ93AT939x7giJm9Idf+buCnuae/7Tezt+X2UWFmVVP6txCZIH0TERnD3Xea2ceA75tZDBgE3kf2IS3NuW2dZOcRAN4D/J/cgT7/bp3vBr5gZuty+3jnFP41RCZMdx8VmSAzO+HuM8KuQ2SyaWhIRCTidEYgIhJxOiMQEYk4BYGISMQpCEREIk5BICIScQoCEZGI+/+pYe8SJtmyUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=list(output.keys()), y=[output[epoch][0][1][-1][1] for epoch in output])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"F1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще во время препроцессинга текстов заголовков и построения корпуса автор обратил внимание на очень хорошее пересечение токенов заголовков одного товара. Возникла идея пропустить этап построения эмбеддингов, а перейти сразу к подсчету расстояния. Причем в простейшем случае использовать примитивное пересечение множеств токенов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим множества токенов, считаем попарные пересечения (используем разреженные матрицы), варьируем порог и смотрим на качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "7Zb6ndc3N3yU"
   },
   "outputs": [],
   "source": [
    "setted_series = df[\"text\"].apply(lambda x: set(x))\n",
    "pairwise_inters = [setted_series.apply(lambda x: len(x & row)).to_numpy() for row in setted_series]\n",
    "\n",
    "X = np.array(pairwise_inters)\n",
    "sparse_X = csr_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "078yE0adN3yU",
    "outputId": "691c764a-41f9-459a-9300-f3d6c65c1038"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 529700/529700 [02:49<00:00, 3133.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESH: 2, F1: 0.47134041740652705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215777/215777 [01:06<00:00, 3227.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESH: 3, F1: 0.5606379513777408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114704/114704 [00:34<00:00, 3347.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESH: 4, F1: 0.5390206265571864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69504/69504 [00:20<00:00, 3428.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESH: 5, F1: 0.4622199113068653\n"
     ]
    }
   ],
   "source": [
    "for thresh in range(2, 6):\n",
    "    rows, cols = (sparse_X > thresh).nonzero()\n",
    "    df[\"inter_pred\"] = \"\"\n",
    "    for i, j in tqdm(list(zip(rows, cols))):\n",
    "        df[\"inter_pred\"][i] += \" \" + df[\"posting_id\"][j]\n",
    "    df[\"inter_pred\"].apply(lambda string: string[1:])\n",
    "    print(f\"THRESH: {thresh}, F1: {f1_score(df['matches'], df['inter_pred']).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Качество 0.56**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Classification problem***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотим использовать машинное обучение вместо ручного подбора порога. Переформулируем исходную задачу. Пусть объект - не заголовок, как раньше, а пара заголовков. Целевая переменная - отвечают ли заголовки в паре одному товару. Имеем бинарный таргет и бинарную задачу классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решейпим датафрейм в обучающую выборку под задачу классификации. 1 классом считаем заголовки одного товара, 0 классом - разных. Очевидно, как получить все объекты 1 класса по исходной выборке. Для получения объектов 0 класса можем использовать случайные пары заголовков разных товаров. \n",
    "\n",
    "По исходной выборке строим подвыборку объектов 1 класса. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего пар 1 класса 55654\n"
     ]
    }
   ],
   "source": [
    "aggregated = df.groupby(\"label\")[\"text\"].agg(lambda x: list(combinations(x, 2))).explode()\n",
    "\n",
    "pair_df = pd.DataFrame(\n",
    "    aggregated.to_list(),\n",
    "    columns=[\"title1\", \"title2\"]\n",
    ")\n",
    "\n",
    "pair_df[\"target\"] = aggregated.index\n",
    "pair_df[\"class\"] = 1\n",
    "\n",
    "positive_class_size = len(aggregated)\n",
    "print(f\"Всего пар 1 класса {positive_class_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайность для построения объектов 0 класса будем моделировать сдвигом. В подвыборке объектов 1 класса получены два столбца, отвечающие заголовкам. Сдвинем один столбец вверх, а второй вниз так, что на пересечении строк окажутся заголовки разных товаров. \n",
    "\n",
    "Берем сдвиг в 2000, проверяем что все товары действительно разные (таргет не совпадает)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pair_df[:-2000][\"target\"].to_numpy() == pair_df[2000:][\"target\"].to_numpy()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = pd.DataFrame(pair_df[\"title1\"][2000:].reset_index(drop=True))\n",
    "neg_df[\"title2\"] = pair_df[\"title1\"][:-2000].reset_index(drop=True)\n",
    "neg_df[\"class\"] = 0\n",
    "pair_df = pair_df.drop(\"target\", axis=1)\n",
    "pair_df = pd.concat([pair_df, neg_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговая новая обучающая выборка под задачу классификации (110к объектов против исходных 20к). Важное замечание: классы заведомо построены сбалансированно, примерно поровну с погрешностью в 4к сдвинутых заголовков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title1</th>\n",
       "      <th>title2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[paper, bag, victoria, secret]</td>\n",
       "      <td>[paper, bag, victoria, secret]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[maling, tt, canned, pork, luncheon, meat, 397...</td>\n",
       "      <td>[maling, ham, pork, luncheon, meat, tt, 397gr]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[daster, batik, lengan, pendek, motif, acak, c...</td>\n",
       "      <td>[daster, piyama, katun, jepangtidak, bisa, pil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[kulot, plisket, salur, candy, plisket, wish, ...</td>\n",
       "      <td>[kulot, plisket, momblu]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[logu, tempelan, kulkas, magnet, angka, tempel...</td>\n",
       "      <td>[10pcs, magnet, kulkas, model, angka, 09, baha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53649</th>\n",
       "      <td>[fygalery, j189, jam, tangan, transparan, mere...</td>\n",
       "      <td>[gamis, murah, gamis, hyget]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53650</th>\n",
       "      <td>[flex, tape, isolasi, ajaib, super, kuat, rubb...</td>\n",
       "      <td>[restock, jilbabhijab, segi, tiga, instan, haw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53651</th>\n",
       "      <td>[tempered, glass, samsung, galaxy, a30, a50, a...</td>\n",
       "      <td>[mouse, pad, gaming, hunter, original, asli]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53652</th>\n",
       "      <td>[lampu, huruf, az, dan, angka, 09, xe2x9dxa4xe...</td>\n",
       "      <td>[st, ives, glowing, apricot, sheet, mask, mask...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53653</th>\n",
       "      <td>[sprei, lady, rose, 180x200, king, terlaris, k...</td>\n",
       "      <td>[parfum, mobil, pengharum, mobil, pewangi, mob...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109308 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title1  \\\n",
       "0                         [paper, bag, victoria, secret]   \n",
       "1      [maling, tt, canned, pork, luncheon, meat, 397...   \n",
       "2      [daster, batik, lengan, pendek, motif, acak, c...   \n",
       "3      [kulot, plisket, salur, candy, plisket, wish, ...   \n",
       "4      [logu, tempelan, kulkas, magnet, angka, tempel...   \n",
       "...                                                  ...   \n",
       "53649  [fygalery, j189, jam, tangan, transparan, mere...   \n",
       "53650  [flex, tape, isolasi, ajaib, super, kuat, rubb...   \n",
       "53651  [tempered, glass, samsung, galaxy, a30, a50, a...   \n",
       "53652  [lampu, huruf, az, dan, angka, 09, xe2x9dxa4xe...   \n",
       "53653  [sprei, lady, rose, 180x200, king, terlaris, k...   \n",
       "\n",
       "                                                  title2  class  \n",
       "0                         [paper, bag, victoria, secret]      1  \n",
       "1         [maling, ham, pork, luncheon, meat, tt, 397gr]      1  \n",
       "2      [daster, piyama, katun, jepangtidak, bisa, pil...      1  \n",
       "3                               [kulot, plisket, momblu]      1  \n",
       "4      [10pcs, magnet, kulkas, model, angka, 09, baha...      1  \n",
       "...                                                  ...    ...  \n",
       "53649                       [gamis, murah, gamis, hyget]      0  \n",
       "53650  [restock, jilbabhijab, segi, tiga, instan, haw...      0  \n",
       "53651       [mouse, pad, gaming, hunter, original, asli]      0  \n",
       "53652  [st, ives, glowing, apricot, sheet, mask, mask...      0  \n",
       "53653  [parfum, mobil, pengharum, mobil, pewangi, mob...      0  \n",
       "\n",
       "[109308 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Feature Engineering***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пойдем дальше в рассчете расстояний на заголовках. Заголовки - суть обычные строки из предобработанных токенов. Известно расстояние Левенштейна на строках (число перестановок). Используем некоторые его обобщения, а также другие строковые расстояния из библиотеки jellyfish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_df[\"title1_str\"] = pair_df[\"title1\"].apply(lambda x: \" \".join(x))\n",
    "pair_df[\"title2_str\"] = pair_df[\"title2\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JF ENGINEERING OVER (9.6 sec)\n"
     ]
    }
   ],
   "source": [
    "pair_df[\"title1_str\"] = pair_df[\"title1\"].apply(lambda x: \" \".join(x))\n",
    "pair_df[\"title2_str\"] = pair_df[\"title2\"].apply(lambda x: \" \".join(x))\n",
    "pair_df[\"numbers1\"] = pair_df[\"title1_str\"].apply(lambda x: set(re.findall(r'[0-9]+', x)))\n",
    "pair_df[\"numbers2\"] = pair_df[\"title2_str\"].apply(lambda x: set(re.findall(r'[0-9]+', x)))\n",
    "\n",
    "s = time.time()\n",
    "\n",
    "pair_df[\"levenshtein_distance\"] = pair_df.apply(\n",
    "    lambda x: jf.levenshtein_distance(x[\"title1_str\"], x[\"title2_str\"]), axis=1)\n",
    "\n",
    "pair_df[\"damerau_levenshtein_distance\"] = pair_df.apply(\n",
    "    lambda x: jf.damerau_levenshtein_distance(x[\"title1_str\"], x[\"title2_str\"]), axis=1)\n",
    "\n",
    "pair_df[\"hamming_distance\"] = pair_df.apply(\n",
    "    lambda x: jf.hamming_distance(x[\"title1_str\"], x[\"title2_str\"]), axis=1)\n",
    "\n",
    "pair_df[\"jaro_similarity\"] = pair_df.apply(\n",
    "    lambda x: jf.jaro_similarity(x[\"title1_str\"], x[\"title2_str\"]), axis=1)\n",
    "\n",
    "pair_df[\"jaro_winkler_similarity\"] = pair_df.apply(\n",
    "    lambda x: jf.jaro_winkler_similarity(x[\"title1_str\"], x[\"title2_str\"]), axis=1)\n",
    "\n",
    "pair_df[\"match_rating_comparison\"] = pair_df.apply(\n",
    "    lambda x: jf.match_rating_comparison(x[\"title1_str\"], x[\"title2_str\"]), axis=1).fillna(False).astype(int)\n",
    "\n",
    "print(f\"JF ENGINEERING OVER ({round(time.time() - s, 2)} sec)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем расстояния на строках из библиотеки FuzzyWuzzy - расстояния, учитывающие порядок, повторения, вхождение одной строки в другую. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUZZ ENGINEERING OVER (436.63 sec)\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "pair_df[\"ratio\"] = pair_df.apply(\n",
    "    lambda x: fuzz.ratio(x[\"title1_str\"], x[\"title2_str\"]), axis=1)\n",
    "\n",
    "pair_df[\"token_sort_ratio\"] = pair_df.apply(\n",
    "    lambda x: fuzz.token_sort_ratio(x[\"title1_str\"], x[\"title2_str\"]), axis=1)\n",
    "\n",
    "pair_df[\"token_set_ratio\"] = pair_df.apply(\n",
    "    lambda x: fuzz.token_set_ratio(x[\"title1_str\"], x[\"title2_str\"]), axis=1)\n",
    "\n",
    "pair_df[\"partial_ratio\"] = pair_df.apply(\n",
    "    lambda x: fuzz.partial_ratio(x[\"title1_str\"], x[\"title2_str\"]), axis=1)\n",
    "\n",
    "pair_df[\"WRatio\"] = pair_df.apply(\n",
    "    lambda x: fuzz.WRatio(x[\"title1_str\"], x[\"title2_str\"]), axis=1)\n",
    "\n",
    "pair_df[\"UQRatio\"] = pair_df.apply(\n",
    "    lambda x: fuzz.UQRatio(x[\"title1_str\"], x[\"title2_str\"]), axis=1)\n",
    "\n",
    "pair_df[\"QRatio\"] = pair_df.apply(\n",
    "    lambda x: fuzz.QRatio(x[\"title1_str\"], x[\"title2_str\"]), axis=1)\n",
    "\n",
    "print(f\"FUZZ ENGINEERING OVER ({round(time.time() - s, 2)} sec)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забудем и про идею с которой все начиналось - считаем мощность пересечения, и связанное с ним (нормировкой) расстояние Жаккарда. Еще одна плодотворная идея - учитывать только числовые значения (в заголовках товаров много неймингов моделей с числами, в духе \"PS5\", \"GTX3080\" и т.д.). Аналогично считаем пересечения и Жаккарда только на числах. Дополнительно добавим признаки длин каждого заголовка и суммы длин, то же для чисел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBERS ENGINEERING OVER (10.74 sec)\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "pair_df[\"intersection\"] = pair_df.apply(\n",
    "    lambda x: len(set(x[\"title1\"]) & set(x[\"title2\"])), axis=1)\n",
    "\n",
    "pair_df[\"jaccard\"] = pair_df.apply(\n",
    "    lambda x: len(set(x[\"title1\"]) & set(x[\"title2\"])) / len(set(x[\"title1\"]) | set(x[\"title2\"])), axis=1)\n",
    "\n",
    "pair_df[\"len1\"] = pair_df.apply(\n",
    "    lambda x: len(x[\"title1\"]), axis=1)\n",
    "\n",
    "pair_df[\"len2\"] = pair_df.apply(\n",
    "    lambda x: len(x[\"title2\"]), axis=1)\n",
    "\n",
    "pair_df[\"lens\"] = pair_df.apply(\n",
    "    lambda x: len(x[\"title1\"]) + len(x[\"title2\"]), axis=1)\n",
    "\n",
    "pair_df[\"numbers_intersection\"] = pair_df.apply(\n",
    "    lambda x: len(set(x[\"numbers1\"]) & set(x[\"numbers2\"])), axis=1)\n",
    "\n",
    "pair_df[\"numbers_union\"] = pair_df.apply(\n",
    "    lambda x: len(set(x[\"numbers1\"]) | set(x[\"numbers2\"])), axis=1)\n",
    "\n",
    "pair_df[\"numbers_jaccard\"] = (pair_df[\"numbers_intersection\"] / pair_df[\"numbers_union\"]).fillna(0)\n",
    "\n",
    "pair_df[\"len_numbers1\"] = pair_df[\"numbers1\"].apply(lambda x: len(x))\n",
    "\n",
    "pair_df[\"len_numbers2\"] = pair_df[\"numbers1\"].apply(lambda x: len(x))\n",
    "\n",
    "print(f\"NUMBERS ENGINEERING OVER ({round(time.time() - s, 2)} sec)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Training***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем решать задачу классификации градиентным бустингом XGBoost, гиперпараметры тюним с помощью optuna (некоторая рутина тюнинга опущена в финальном ноутбуке)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['levenshtein_distance', 'damerau_levenshtein_distance',\n",
    "       'hamming_distance', 'jaro_similarity', 'jaro_winkler_similarity',\n",
    "       'match_rating_comparison', 'ratio', 'token_sort_ratio',\n",
    "       'token_set_ratio', 'partial_ratio', 'WRatio', 'UQRatio', 'QRatio',\n",
    "       'intersection', 'jaccard', 'len1', 'len2', 'lens',\n",
    "       'numbers_intersection', 'numbers_union', 'numbers_jaccard',\n",
    "       'len_numbers1', 'len_numbers2']\n",
    "\n",
    "X = pair_df[features].values\n",
    "y = pair_df[\"class\"].values\n",
    "\n",
    "X_train_pd, X_val_pd, y_train_pd, y_val_pd = train_test_split(\n",
    "    pair_df,\n",
    "    pair_df[\"class\"],\n",
    "    test_size=0.3,\n",
    "    random_state=1337,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val = X_train_pd[features].values, X_val_pd[features].values\n",
    "y_train, y_val = y_train_pd.values, y_val_pd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt(X_train, y_train, X_test, y_test, trial):\n",
    "    # based on https://www.kaggle.com/snakayama/xgboost-using-optuna\n",
    "    n_estimators = trial.suggest_int('n_estimators', 600, 800)\n",
    "    max_depth = trial.suggest_int('max_depth', 18, 30)\n",
    "    learning_rate = trial.suggest_discrete_uniform('learning_rate', 0.03, 0.1, 0.05)\n",
    "    scale_pos_weight = trial.suggest_int('scale_pos_weight', 4, 6)\n",
    "    subsample = trial.suggest_discrete_uniform('subsample', 0.7, 0.9, 0.1)\n",
    "    colsample_bytree = trial.suggest_discrete_uniform('colsample_bytree', 0.5, 0.8, 0.1)\n",
    "\n",
    "    xgboost_tuna = XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=1337, \n",
    "        min_child_weight=1,\n",
    "        learning_rate=learning_rate,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree, \n",
    "        eval_metric=\"logloss\"\n",
    "    )\n",
    "    xgboost_tuna.fit(X_train, y_train)\n",
    "    tuna_pred_test = xgboost_tuna.predict(X_test)\n",
    "    \n",
    "    return (1.0 - (f1_sklearn(y_test, tuna_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-27 23:52:07,126]\u001b[0m A new study created in memory with name: no-name-b3118812-8a5a-4267-abef-0f9bc32326db\u001b[0m\n",
      "\u001b[32m[I 2021-10-27 23:53:22,846]\u001b[0m Trial 0 finished with value: 0.014277108433734864 and parameters: {'n_estimators': 688, 'max_depth': 18, 'learning_rate': 0.03, 'scale_pos_weight': 5, 'subsample': 0.8999999999999999, 'colsample_bytree': 0.8}. Best is trial 0 with value: 0.014277108433734864.\u001b[0m\n",
      "\u001b[32m[I 2021-10-27 23:54:52,394]\u001b[0m Trial 1 finished with value: 0.014014044181911323 and parameters: {'n_estimators': 747, 'max_depth': 26, 'learning_rate': 0.03, 'scale_pos_weight': 5, 'subsample': 0.8999999999999999, 'colsample_bytree': 0.7}. Best is trial 1 with value: 0.014014044181911323.\u001b[0m\n",
      "\u001b[32m[I 2021-10-27 23:56:45,220]\u001b[0m Trial 2 finished with value: 0.01419315956004219 and parameters: {'n_estimators': 778, 'max_depth': 27, 'learning_rate': 0.03, 'scale_pos_weight': 5, 'subsample': 0.8999999999999999, 'colsample_bytree': 0.8}. Best is trial 1 with value: 0.014014044181911323.\u001b[0m\n",
      "\u001b[32m[I 2021-10-27 23:57:59,111]\u001b[0m Trial 3 finished with value: 0.014038681689461985 and parameters: {'n_estimators': 602, 'max_depth': 23, 'learning_rate': 0.03, 'scale_pos_weight': 6, 'subsample': 0.7999999999999999, 'colsample_bytree': 0.7}. Best is trial 1 with value: 0.014014044181911323.\u001b[0m\n",
      "\u001b[32m[I 2021-10-27 23:59:28,421]\u001b[0m Trial 4 finished with value: 0.014285714285714235 and parameters: {'n_estimators': 757, 'max_depth': 22, 'learning_rate': 0.03, 'scale_pos_weight': 5, 'subsample': 0.7, 'colsample_bytree': 0.8}. Best is trial 1 with value: 0.014014044181911323.\u001b[0m\n",
      "\u001b[32m[I 2021-10-28 00:00:44,361]\u001b[0m Trial 5 finished with value: 0.014444678990380266 and parameters: {'n_estimators': 779, 'max_depth': 23, 'learning_rate': 0.08, 'scale_pos_weight': 4, 'subsample': 0.8999999999999999, 'colsample_bytree': 0.5}. Best is trial 1 with value: 0.014014044181911323.\u001b[0m\n",
      "\u001b[32m[I 2021-10-28 00:02:03,454]\u001b[0m Trial 6 finished with value: 0.01449712167334749 and parameters: {'n_estimators': 621, 'max_depth': 27, 'learning_rate': 0.03, 'scale_pos_weight': 4, 'subsample': 0.7, 'colsample_bytree': 0.7}. Best is trial 1 with value: 0.014014044181911323.\u001b[0m\n",
      "\u001b[32m[I 2021-10-28 00:03:03,010]\u001b[0m Trial 7 finished with value: 0.014560911639685314 and parameters: {'n_estimators': 787, 'max_depth': 22, 'learning_rate': 0.08, 'scale_pos_weight': 6, 'subsample': 0.7, 'colsample_bytree': 0.5}. Best is trial 1 with value: 0.014014044181911323.\u001b[0m\n",
      "\u001b[32m[I 2021-10-28 00:04:08,255]\u001b[0m Trial 8 finished with value: 0.014408005787316158 and parameters: {'n_estimators': 611, 'max_depth': 18, 'learning_rate': 0.03, 'scale_pos_weight': 4, 'subsample': 0.8999999999999999, 'colsample_bytree': 0.6}. Best is trial 1 with value: 0.014014044181911323.\u001b[0m\n",
      "\u001b[32m[I 2021-10-28 00:05:15,595]\u001b[0m Trial 9 finished with value: 0.014497995599360936 and parameters: {'n_estimators': 650, 'max_depth': 27, 'learning_rate': 0.03, 'scale_pos_weight': 4, 'subsample': 0.7999999999999999, 'colsample_bytree': 0.6}. Best is trial 1 with value: 0.014014044181911323.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(functools.partial(opt, X_train, y_train, X_val, y_val), n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH xgb fitting (68.661 sec))\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(eval_metric=\"logloss\", **study.best_params)\n",
    "s = time.time()\n",
    "xgb.fit(X_train, y_train)\n",
    "print(f\"FINISH xgb fitting ({round(time.time() - s, 3)} sec))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Evaluation***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на классические метрики бинарной классификации. \n",
    "\n",
    "ВАЖНО: здесь F1 для задачи классификации, не путать с построчным F1, который был до этого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.9855640276061601\n",
      "ROC AUC = 0.9855073960471465\n",
      "============\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     16096\n",
      "           1       0.99      0.98      0.99     16697\n",
      "\n",
      "    accuracy                           0.99     32793\n",
      "   macro avg       0.99      0.99      0.99     32793\n",
      "weighted avg       0.99      0.99      0.99     32793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"F1 = {f1_sklearn(y_val, y_pred)}\")\n",
    "print(f\"ROC AUC = {roc_auc_score(y_val, y_pred)}\")\n",
    "print(\"============\")\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бустинг решает задачу с почти 100% качеством. Тем не менее, в реальной жизни качество будет меньше, т.к. во-первых реальное распределение пар строк смещено (в реальности примеров класса 0 гораздо больше). Во-вторых, объект - пара строк содержит в себе исходные строки, а эти исходные строки могут попасть и в контроль. Поэтому для оценки на реальных данных стоит дополнительно набрать в валидационную выборку совсем уникальные строки, которые модель вообще не видела (хоть и признаковое описание не содержит самих строк, а лишь попарные расстояния).\n",
    "\n",
    "Посмотрим на важность признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intersection</th>\n",
       "      <td>683.008362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard</th>\n",
       "      <td>199.157211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WRatio</th>\n",
       "      <td>15.587306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numbers_intersection</th>\n",
       "      <td>5.475574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numbers_jaccard</th>\n",
       "      <td>3.890963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_set_ratio</th>\n",
       "      <td>3.793882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <td>3.109800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QRatio</th>\n",
       "      <td>3.002324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_ratio</th>\n",
       "      <td>2.786645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_rating_comparison</th>\n",
       "      <td>2.749792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numbers_union</th>\n",
       "      <td>2.612166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UQRatio</th>\n",
       "      <td>2.339201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lens</th>\n",
       "      <td>2.320755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <td>2.197624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_numbers1</th>\n",
       "      <td>2.194899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len_numbers2</th>\n",
       "      <td>2.131955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaro_winkler_similarity</th>\n",
       "      <td>2.076622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len2</th>\n",
       "      <td>2.058212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio</th>\n",
       "      <td>2.034966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len1</th>\n",
       "      <td>2.003465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaro_similarity</th>\n",
       "      <td>1.963837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_distance</th>\n",
       "      <td>1.943248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>damerau_levenshtein_distance</th>\n",
       "      <td>1.940539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Importance\n",
       "intersection                  683.008362\n",
       "jaccard                       199.157211\n",
       "WRatio                         15.587306\n",
       "numbers_intersection            5.475574\n",
       "numbers_jaccard                 3.890963\n",
       "token_set_ratio                 3.793882\n",
       "token_sort_ratio                3.109800\n",
       "QRatio                          3.002324\n",
       "partial_ratio                   2.786645\n",
       "match_rating_comparison         2.749792\n",
       "numbers_union                   2.612166\n",
       "UQRatio                         2.339201\n",
       "lens                            2.320755\n",
       "levenshtein_distance            2.197624\n",
       "len_numbers1                    2.194899\n",
       "len_numbers2                    2.131955\n",
       "jaro_winkler_similarity         2.076622\n",
       "len2                            2.058212\n",
       "ratio                           2.034966\n",
       "len1                            2.003465\n",
       "jaro_similarity                 1.963837\n",
       "hamming_distance                1.943248\n",
       "damerau_levenshtein_distance    1.940539"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_importance_scores = xgb.get_booster().get_score(importance_type=\"gain\")\n",
    "importance_scores = {features[int(key[1:])]: \n",
    "                     [raw_importance_scores[key]] for key in raw_importance_scores}\n",
    "\n",
    "pd.DataFrame.from_dict(\n",
    "    importance_scores, orient=\"index\", columns=[\"Importance\"]\n",
    ").sort_values(\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приятно отметить, что **самый важный признак модели - мощность пересечения**, с которой все и начиналось.\n",
    "\n",
    "Также важны расстояние Жаккарда (которое связано с пересечением), WRatio - усреднение строковых расстояний библиотеки FuzzyWuzzy.\n",
    "\n",
    "Отдельно отметим важность пересечения и Жаккарда только на числовых токенах (пример с PS5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, оценим решение с помощью исходной построчной F1 меры. Решейпим пары обратно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pairs_back(pairs, y): # pairs = X_val_pd, y = class\n",
    "    output = {}\n",
    "    for _, pair in pairs[y == 1].iterrows():\n",
    "        title1, title2 = pair[\"title1_str\"], pair[\"title2_str\"]\n",
    "        if title1 in output:\n",
    "            output[title1].add(title2)\n",
    "        else:\n",
    "            output[title1] = {title1, title2}\n",
    "        if title2 in output:\n",
    "            output[title2].add(title1)\n",
    "        else:\n",
    "            output[title2] = {title1, title2}\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def honest_evaluation(X, y, y_pred):   \n",
    "    converted_dict_true = convert_pairs_back(X, y)\n",
    "    converted_dict_pred = convert_pairs_back(X, y_pred)\n",
    "    codes = {key: i for i, key in enumerate(set(converted_dict_true.keys()) | set(converted_dict_pred.keys()))}\n",
    "\n",
    "    true_col = []\n",
    "    pred_col = []\n",
    "\n",
    "    for key in converted_dict_true:\n",
    "        if key in converted_dict_pred:\n",
    "            pred_set = converted_dict_pred[key]\n",
    "            pred_col.append(\" \".join([str(codes[val]) for val in pred_set]))\n",
    "        else:\n",
    "            pred_col.append(\" \")\n",
    "\n",
    "        true_set = converted_dict_true[key]\n",
    "        true_col.append(\" \".join([str(codes[val]) for val in true_set]))\n",
    "        \n",
    "    print(f\"Построчный F1 = {f1_score(pd.Series(true_col), pd.Series(pred_col)).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Построчный F1 = 0.9837552217331322\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "honest_evaluation(X_val_pd, y_val_pd, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Качество 0.984**. Это построчная F1-мера на отложенной выборке. Помним, что нужно делать поправку на некорректный подсчет этой меры, предложенный в условии, а также на смещенное распределение класса 0 в реальной жизни."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обобщение на большие данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые размышления по обобщению предложенных решений на большие данные. Понятное дело, что подсчитывать полную матрицу попарных расстояний на всех объектах - затруднительно (хотя кажется возможным, если разбивать на блоки). \n",
    "\n",
    "Я бы предложил посмотреть на задачу со стороны задачи классификации. Нужно абстрагироваться до работы с парами объектов - например, смотреть на батчи пар заголовков. На парах можно быстро считать все строковые расстояния и быстро классифицировать пару. Если есть обученный энкодер (тем не менее, стоит задуматься - решать задачу нейронками на таких данных, не равно ли стрельбе из пушек по воробьям?) - можно так же быстро получать эмбеддинги для заголовков в паре и считать расстояния уже на эмбеддингах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что можно улучшить?\n",
    "\n",
    "В пайплайне с metric learning усложнить энкодер (добавить аттеншн, поменять LSTM на GRU, посмотреть на сверточные сети вместо рекуррентных или вообще на берт), потюнить лосс (в том же pytorch-metric-learning много более современных).\n",
    "\n",
    "В пайплайне с бустингом и строковым расстояниями почистить нагенеренные признаки, оставить минимальный набор, тем не менее дающий высокое качество - чтобы иметь возможность быстро посчитать признаки на паре строк.\n",
    "\n",
    "Ну и наконец, совместить эти две идеи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJ7hQcMPN3yU"
   },
   "source": [
    "## Ключевые референсы:\n",
    "**(Код писался самостоятельно, если противное не оговорено в комментарии)**\n",
    "\n",
    "Архитектура энкодера:\n",
    "\n",
    "-    https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial\n",
    "\n",
    "-    https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "\n",
    "Паддинг и пакинг батчей последовательностей произвольной длины в RNN:\n",
    "\n",
    "-    https://gist.github.com/HarshTrivedi/f4e7293e941b17d19058f6fb90ab0fec\n",
    "\n",
    "Обучение metric-learning архитектур:\n",
    "\n",
    "-    https://kevinmusgrave.github.io/pytorch-metric-learning/\n",
    "\n",
    "Генерация признаков на паре строк:\n",
    "\n",
    "-    https://jellyfish.readthedocs.io/en/latest/comparison.html\n",
    "\n",
    "-    https://habr.com/ru/post/491448/\n",
    "\n",
    "-    https://tirinox.ru/fuzzywuzzy-python/\n",
    "\n",
    "Подбор гиперпараметров с помощью optuna:\n",
    "\n",
    "-    https://www.kaggle.com/snakayama/xgboost-using-optuna"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "test_example-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
